# -*- coding: utf-8 -*-
"""A3 Modelos Descritivos - OK

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RTO55CyJAppIrdHiyMOwndJBsA27ymJY

Importando Bibliotecas
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler, StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, mean_squared_error, r2_score
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.cluster import KMeans
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay

"""Transformaçao"""

df = pd.read_csv('Sleep_health_and_lifestyle_dataset.csv')

def avaliando_Transf(df):
    plt.figure(figsize=(10, 6))
    sns.histplot(df['Age'], kde=True, bins=20)
    plt.title('Distribuição de Idade')
    plt.xlabel('Idade')
    plt.ylabel('Frequência')
    plt.show()

idade_descritiva = df['Age'].describe()
    print(idade_descritiva)

avaliando_Transf(df)

idade_descritiva = df['Age'].describe()
print(idade_descritiva)

# faixas etárias
bins = [27, 34, 42, 50, 59]
labels = ['27-34', '35-42', '43-50', '51-59']
df['Faixa Etária'] = pd.cut(df['Age'], bins=bins, labels=labels, right=True)

# distribuição dentro das faixas etárias
faixa_etaria_distribuicao = df['Faixa Etária'].value_counts().sort_index()
faixa_etaria_distribuicao



"""Variaveis Categoricas"""

categorical_columns = ['Gender', 'Occupation', 'BMI Category', 'Blood Pressure', 'Sleep Disorder', 'Faixa Etária']

df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)

print(df_encoded.head())

"""Normalizaçao"""

numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns

scaler_min_max = MinMaxScaler()
df_min_max_scaled = df.copy()
df_min_max_scaled[numeric_columns] = scaler_min_max.fit_transform(df[numeric_columns])

scaler_z_score = StandardScaler()
df_z_score_scaled = df.copy()
df_z_score_scaled[numeric_columns] = scaler_z_score.fit_transform(df[numeric_columns])

print("Min-Max Scaled Dataset:")
print(df_min_max_scaled.head())

print("\nZ-score Normalized Dataset:")
print(df_z_score_scaled.head())

"""Balanceamento de variavel"""

target_variable = 'Sleep Disorder'

class_distribution = df[target_variable].value_counts()

plt.figure(figsize=(10, 6))
class_distribution.plot(kind='bar')
plt.title('Distribuição das Classes')
plt.xlabel('Classes')
plt.ylabel('Frequência')
plt.show()

print(class_distribution)

"""Variaveis com alta correlaçao"""

x = np.linspace(0, 10, 50, endpoint=True)

h1 = lambda a: a * np.sqrt(x)
h2 = lambda b, c: b * np.exp(x / c)

plt.figure(figsize=(6, 4), dpi=200, facecolor='#e0eeee')
plt.plot(x, h1(0.9), label='h1')
plt.plot(x, h2(1, 9), label='h2')
plt.title('Gráfico de h1 e h2')
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.show()

idade_descritiva = df['Age'].describe()
print(idade_descritiva)

print(df.columns)

numeric_columns = df.select_dtypes(include=['number'])

correlation_matrix = numeric_columns.corr()

print(correlation_matrix)

plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title('Matriz de Correlação')
plt.show()

high_correlation_pairs = []

correlation_threshold = 0.8

for i in range(len(correlation_matrix.columns)):
    for j in range(i):
        if abs(correlation_matrix.iloc[i, j]) > correlation_threshold:
            high_correlation_pairs.append((correlation_matrix.columns[i], correlation_matrix.columns[j]))

print("Pares de variáveis altamente correlacionadas:")
print(high_correlation_pairs)

variables_to_remove = set()
for pair in high_correlation_pairs:
    variables_to_remove.add(pair[1])

df_reduced = df.drop(columns=variables_to_remove)

print("Após a remoção de variáveis altamente correlacionadas:")
print(df_reduced.head())

"""Seleçao das Variaveis"""

df_encoded = pd.get_dummies(df, drop_first=True)

print(df_encoded.columns)

target_variable = 'Sleep Disorder_Sleep Apnea'

X = df_encoded.drop(columns=[target_variable])
y = df_encoded[target_variable]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

select_k_best_anova = SelectKBest(f_classif, k=10)
X_new_anova = select_k_best_anova.fit_transform(X_train, y_train)

print(X_new_anova[:5])

"""Hiperparametrização automática"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

select_k_best_anova = SelectKBest(f_classif, k=10)
X_train_new = select_k_best_anova.fit_transform(X_train, y_train)
X_test_new = select_k_best_anova.transform(X_test)

rfc = RandomForestClassifier()

param_distributions = {
    'n_estimators': [int(x) for x in range(10, 200, 10)],
    'max_features': ['auto', 'sqrt'],
    'max_depth': [int(x) for x in range(10, 110, 10)] + [None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'bootstrap': [True, False]
}

random_search = RandomizedSearchCV(estimator=rfc, param_distributions=param_distributions,
                                   n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)

random_search.fit(X_train_new, y_train)

best_model = random_search.best_estimator_
y_pred = best_model.predict(X_test_new)

print(f"Best Parameters: {random_search.best_params_}")
print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
print(classification_report(y_test, y_pred))

"""Avaliação do modelo"""

rf = RandomForestClassifier(random_state=42, n_estimators=100, max_features='auto', max_depth=10, min_samples_split=2, min_samples_leaf=1, bootstrap=True)

rf.fit(X_train, y_train)

y_pred = rf.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)

conf_matrix = confusion_matrix(y_test, y_pred)

class_report = classification_report(y_test, y_pred)

roc_auc = roc_auc_score(y_test, rf.predict_proba(X_test)[:, 1])

fpr, tpr, thresholds = roc_curve(y_test, rf.predict_proba(X_test)[:, 1])
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

print("Acurácia:", accuracy)
print("Matriz de Confusão:")
print(conf_matrix)
print("Relatório de Classificação:")
print(class_report)
print("ROC-AUC:", roc_auc)

"""Agrupamento: Visualização Scatter Plot"""

X = df.iloc[:, :2]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(df_encoded)

kmeans = KMeans(n_clusters=3, random_state=42)
kmeans.fit(X_scaled)
labels = kmeans.labels_

plt.figure(figsize=(10, 6))
plt.scatter(X.iloc[:, 0], X.iloc[:, 1], c=labels, cmap='viridis', marker='o')
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red', label='Centroids')
plt.title('K-Means Clustering')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.legend()
plt.show()

"""Matriz de Confusao"""

disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=rf.classes_)
disp.plot(cmap='Blues')
plt.title('Matriz de Confusão')
plt.show()

reg = LinearRegression()
reg.fit(X_train, y_train)

y_pred = reg.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

selected_features = ["Sleep Duration", "Heart Rate"]

df_selected = df[selected_features]

print(df_selected.head())

plt.figure(figsize=(10, 6))
plt.scatter(df_selected["Sleep Duration"], df_selected["Heart Rate"], color='blue', label='Dados')
plt.title('Relação entre Duração do Sono e Frequência Cardíaca')
plt.xlabel('Duração do Sono')
plt.ylabel('Frequência Cardíaca')
plt.legend()
plt.show()

